{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File I/O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습목표\n",
    " - File 입출력 이해 및 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* File I/O\n",
    " - I : input, O : ouput 즉, 입출력을 의미함\n",
    " - 간단한 정보들을 저장하고 다시 불러올 수 있다.\n",
    " - DB와 비교하여 검색, 정렬등의 기능을 프로그래머가 구현해야 하기에 잘 쓰이지 않음.\n",
    " - DB와 비교하여 보안등의 이슈가 있음\n",
    " - 그럼에도 가장 기본적인 데이터 저장 방법으로 알맞게 사용됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* write() 함수로 파일에 쓰기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "speech = '''Former Philadelphia 76ers star \n",
    "Allen Iverson was inducted into \n",
    "the Basketball Hall of Fame on Friday night. \n",
    "And then paid tribute to Michael Jordan in his speech.\n",
    "'''\n",
    "# r - 읽기, w - 쓰기, a - 추가\n",
    "fout = open('speech', 'w') \n",
    "fout.write(speech)\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "speech = '''학교 종이 땡땡땡\n",
    "어서 모이자\n",
    "'''\n",
    "\n",
    "fout = open('school', 'w') # 쓰기 모드로 파일을 오픈 (존재한다면, 덮어씀)\n",
    "#fout = open('school', 'a') # 쓰기 모드로 파일을 오픈 (존재한다면, 맨 뒤에서 부터 추가)\n",
    "fout.write(speech)\n",
    "fout.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " + read() method로 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학교 종이 땡땡땡\n",
      "어서 모이자\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fin = open('school', 'r')\n",
    "data = fin.read()\n",
    "fin.close()\n",
    "\n",
    "print data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 연습문제\n",
    " 1. 뉴스 데이터를 파일에 써봅시다.\n",
    " 2. 그리고 다시 읽어와 봅시다.\n",
    " 3. 그리고 해당 뉴스에 스마트폰이라는 단어가 있는지 없는지 판별해 봅시다.\n",
    " 4. 그리고 해당 뉴스를 쓴 기자의 이메일을 추출해봅시다.\n",
    " 4. 힌트) 아래의 get_news_content는 다음 뉴스의 url을 주면 뉴스의 본문을 긁어오는 함수입니다. 이용해서 해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 비츠 포함시 온라인 블루투스 이어폰 시장 점유율 41.4%에 달해 【서울=뉴시스】최현 기자 = 애플이 아이폰 7시리즈를 내놓으면서 혁신 카드로 내세운 무선이어폰 '에어팟'이 큰 인기를 끌며 블루투스 이어폰 시장을 석권한 것으로 나타났다.12일 온라인쇼핑 시장조사기관 슬라이스 인텔리전스에 따르면 지난해 12월13일 출시된 애플의 에어팟은 미국 온라인 블루투스 이어폰 시장 점유율 26.0%를 기록한 것으로 조사됐다.에어팟이 출시되기 전에 점유율 24.1%로 블루투스 이어폰 시장 1위를 기록하고 있던 고급 음향업체 비츠 일렉트로닉스의 점유율은 15.4%로 떨어지며 3위로 밀려났다.다만 비츠는 애플의 오디오 전문 자회사다. 애플은 지난 2014년 비츠를 30억 달러에 인수한 바 있다. 이에 따라 애플의 온라인 블루투스 이어폰 시장 점유율은 41.4%에 달하게 됐다.오디오 전문업체 보스(Bose)는 2위 자리를 유지했지만 에어팟 출시 전 10.5%에서 16.1%로 점유율이 상승했다. 제이버드는 7.5%에서 2.5%로, 플랜트로닉스는 7.8%에서 2.2%로 각각 떨어졌다.소니는 3.6%에서 4.2%로 올랐지만 삼성전자와 LG전자를 비롯한 나머지 회사들의 시장 점유율은 하락했다. LG는 4.6%에서 1.4%로, 삼성은 1.0%에서 0.5%로 급감했다.애플의 에어팟은 블루투스 이어폰 시장의 성장세를 이끌고 있는 것으로 나타났다. 에어팟 출시 이후 미국 온라인 쇼핑몰에서 판매된 이어폰 및 헤드폰 중 75%는 무선 기기로 집계됐다. 에어팟 구매자 85%는 남성이었고, 이 중에 20~30대의 구매율이 35%에 달했다. forgetmenot@newsis.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html5lib\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 174 of the file /usr/local/Cellar/python/2.7.13/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"html5lib\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "# pip install requests\n",
    "# pip install bs4 \n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_news_content(url):\n",
    "    response = requests.get(url)\n",
    "    content = response.text\n",
    "\n",
    "    soup = BeautifulSoup(content)\n",
    "\n",
    "    div = soup.find('div', attrs = {'id' : 'harmonyContainer'})\n",
    "    \n",
    "    content = ''\n",
    "    for paragraph in div.find_all('p'):\n",
    "        content += paragraph.get_text()\n",
    "        \n",
    "    return content.encode('utf-8')\n",
    "        \n",
    "news1 = get_news_content('http://v.media.daum.net/v/20170112152314639')\n",
    "print news1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forgetmenot@newsis.com\n"
     ]
    }
   ],
   "source": [
    "news2 = get_news_content('http://v.media.daum.net/v/20170112152314639')\n",
    "words = news2.split('@')\n",
    "print words[0].split()[-1] + '@' + words[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 위의 이메일 추출은 처리 해야할 예외사항이 많이 존재\n",
    " - 후에 정규표현식을 배운 뒤, 엘레강스하게 해결할 수 있는 방법을 배울 예정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ readline method로 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학교 종이 땡땡땡\n",
      "어서 모이자\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = ''\n",
    "fin2 = open('school', 'r')\n",
    "while True:\n",
    "    line = fin2.readline()\n",
    "    if not line:\n",
    "        break\n",
    "    text += line\n",
    "    \n",
    "fin2.close()\n",
    "\n",
    "print text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* iterator를 이용하여 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학교 종이 땡땡땡\n",
      "\n",
      "어서 모이자\n",
      "\n",
      "학교 종이 땡땡땡\n",
      "어서 모이자\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = ''\n",
    "fin3 = open('school', 'r')\n",
    "for line in fin3:\n",
    "    print line\n",
    "    text += line\n",
    "    \n",
    "fin3.close()\n",
    "print text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* readlines로 리스트 형태로 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 ['\\xed\\x95\\x99\\xea\\xb5\\x90 \\xec\\xa2\\x85\\xec\\x9d\\xb4 \\xeb\\x95\\xa1\\xeb\\x95\\xa1\\xeb\\x95\\xa1\\n', '\\xec\\x96\\xb4\\xec\\x84\\x9c \\xeb\\xaa\\xa8\\xec\\x9d\\xb4\\xec\\x9e\\x90\\n']\n",
      "학교 종이 땡땡땡\n",
      "\n",
      "어서 모이자\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = ''\n",
    "fin4 = open('school', 'r')\n",
    "lines = fin4.readlines() # 각 줄별 문자열로 구성된 리스트를 반환\n",
    "fin4.close()\n",
    "\n",
    "print len(lines), lines\n",
    "for line in lines:\n",
    "    print line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * binary 파일 쓰기/읽기\n",
    "  - 두번째 parameter의 두번째 자리에 'b'를 명시\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000\u0001\u0002\u0003\u0004\u0005\u0006\u0007\b\t\n",
      "\u000b",
      "\f",
      "\r",
      "\u000e\u000f\u0010\u0011\u0012\u0013\u0014\u0015\u0016\u0017\u0018\u0019\u001a\u001b\u001c",
      "\u001d",
      "\u001e",
      "\u001f !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~�������������������������������������������������������������������������������������������������������������������������������� <type 'bytearray'>\n"
     ]
    }
   ],
   "source": [
    "bytes = bytearray(range(256))\n",
    "print bytes, type(bytes)\n",
    "\n",
    "fout = open('bfile', 'wb')\n",
    "fout.write(bytes)\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000\u0001\u0002\u0003\u0004\u0005\u0006\u0007\b\t\n",
      "\u000b",
      "\f",
      "\r",
      "\u000e\u000f\u0010\u0011\u0012\u0013\u0014\u0015\u0016\u0017\u0018\u0019\u001a\u001b\u001c",
      "\u001d",
      "\u001e",
      "\u001f !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~��������������������������������������������������������������������������������������������������������������������������������\n"
     ]
    }
   ],
   "source": [
    "fin = open('bfile', 'rb')\n",
    "bytes = fin.read()\n",
    "print bytes\n",
    "fin.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* with keyword\n",
    " - as keyword와 함께 사용\n",
    " - 블럭 종료 시, 파일을 자동으로 close 시킴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('school', 'r') as fin:\n",
    "    value = fin.read()\n",
    "    print value\n",
    "    \n",
    "fin = open('school', 'r')\n",
    "data = fin.read()\n",
    "fin.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 연습문제 tf-idf 구해보세요.\n",
    " - data_set/tf_idfx.txt를 읽어들여 각 단어들의 tf-idf 를 구하시오\n",
    " - term frequency : 각 문서에서 해당 단어가 나오는 빈도\n",
    " - document frequency : 해당 단어가 얼마나 많은 문서에서 나타나는가 하는 빈도\n",
    " - inverse document frequency : 1/df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python is very concise language compared to the other ones\n",
      "Python has powerful tools and the tools are very nice\n",
      "The tools include debugger profiler and the compiler\n",
      "Python is used widely for many reasons and mostly for web apis\n",
      "The apis built from python is about 2 times faster than ruby\n",
      "python is language and also a specification python can be implemented in any language\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./data_set/tf_idf1.txt', 'r') as fin:\n",
    "    value = fin.read()\n",
    "    print value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('python', 6.0), ('the', 5.333333333333333), ('weather', 5.0), ('we', 3.0), ('language', 3.0), ('tools', 3.0), ('of', 3.0), ('and', 3.0), ('is', 2.6666666666666665), ('they', 2.0), ('for', 2.0), ('forecast', 2.0), ('learning', 2.0), ('apis', 2.0), ('have', 2.0), ('machine', 2.0), ('be', 1.5), ('can', 1.5), ('predict', 1.5), ('in', 1.5), ('very', 1.5), ('to', 1.3333333333333333), ('are', 1.3333333333333333), ('people', 1.0), ('debugger', 1.0), ('web', 1.0), ('with', 1.0), ('better', 1.0), ('going', 1.0), ('include', 1.0), ('widely', 1.0), ('ones', 1.0), ('using', 1.0), ('compiler', 1.0), ('this', 1.0), ('friends.', 1.0), ('concise', 1.0), ('intelligence', 1.0), ('hard', 1.0), ('implemented', 1.0), ('out', 1.0), ('specification', 1.0), ('artificial', 1.0), ('bunch', 1.0), ('houses', 1.0), ('super', 1.0), ('about', 1.0), ('many', 1.0), ('computers', 1.0), ('days', 1.0), ('times', 1.0), ('supervised', 1.0), ('however,', 1.0), ('features', 1.0), ('classification', 1.0), ('reasons', 1.0), ('powerful', 1.0), ('one', 1.0), ('from', 1.0), ('there', 1.0), ('their', 1.0), ('2', 1.0), ('analyze', 1.0), ('today', 1.0), ('more', 1.0), ('mostly', 1.0), ('ruby', 1.0), ('than', 1.0), ('has', 1.0), ('these', 1.0), ('profiler', 1.0), ('will', 1.0), ('anywhere', 1.0), ('result', 1.0), ('it', 1.0), ('learnin', 1.0), ('any', 1.0), ('incorrect', 1.0), ('compared', 1.0), ('built', 1.0), ('regression', 1.0), ('also', 1.0), ('other', 1.0), ('branch', 1.0), ('classify', 1.0), ('nice', 1.0), ('used', 1.0), ('price', 1.0), ('data', 1.0), ('a', 1.0), ('faster', 1.0), ('sometimes', 1.0)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from collections import OrderedDict\n",
    "\n",
    "class TFIDFCaculator(object):\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.tf_dict = defaultdict(int)\n",
    "        self.df_dict = defaultdict(int)\n",
    "\n",
    "    def build_tf_dict(self):\n",
    "        for root, dirs, files in os.walk(self.path):\n",
    "            for f in files:\n",
    "                with open(os.path.join(self.path, f), 'r') as fout:\n",
    "                    data = fout.read()\n",
    "                    words = [word.lower() for word in data.split()] \n",
    "\n",
    "                    for w in words:\n",
    "                        self.tf_dict[w] += 1\n",
    "                        \n",
    "    def build_df_dict(self):\n",
    "        for key in self.tf_dict:\n",
    "            for root, dirs, files in os.walk(self.path):\n",
    "                for f in files:\n",
    "                    with open(os.path.join(self.path, f)) as fout:\n",
    "                        data = fout.read()\n",
    "                        words = [word.lower() for word in data.split()]  \n",
    "                        if key in words:\n",
    "                            self.df_dict[key] += 1\n",
    "                            \n",
    "    def get_tf_idf_dict(self, reverse = True):\n",
    "        tf_idf_dict = {}\n",
    "        \n",
    "        for key, value in self.tf_dict.items():\n",
    "            tf_idf_dict[key] = float(value) / self.df_dict[key]\n",
    "            \n",
    "        tf_idf_dict = OrderedDict(sorted(tf_idf_dict.items(), key = lambda x : x[1], reverse = reverse))\n",
    "        return tf_idf_dict\n",
    "            \n",
    "            \n",
    "path = os.getcwd() + '/data_set'            \n",
    "tf_idf = TFIDFCaculator(path)            \n",
    "\n",
    "tf_idf.build_tf_dict()\n",
    "tf_idf.build_df_dict()\n",
    "print tf_idf.get_tf_idf_dict()\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* csv 파일 형식\n",
    " - comma separated value \n",
    " - 즉, 콤마로 구별된 데이터를 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * csv 파일 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'city', 'population', 'area'] <type 'list'>\n",
      "['1', 'pangyo', '1000', '230'] <type 'list'>\n",
      "['2', 'seoul', '2000', '400'] <type 'list'>\n",
      "['3', 'busan', '5000', '500'] <type 'list'>\n",
      "['4', 'jeju', '200', '200'] <type 'list'>\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('sample.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        print row, type(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', 'pangyo', '1000', '230'] <type 'list'>\n",
      "['2', 'seoul', '2000', '400'] <type 'list'>\n",
      "['3', 'busan', '5000', '500'] <type 'list'>\n",
      "['4', 'jeju', '200', '200'] <type 'list'>\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('sample.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    reader.next()\n",
    "    for row in reader:\n",
    "        print row, type(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * csv 파일 쓰기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', 'pangyo', '1000', '230'] <type 'list'>\n",
      "['2', 'seoul', '2000', '400'] <type 'list'>\n",
      "['3', 'busan', '5000', '500'] <type 'list'>\n",
      "['4', 'jeju', '200', '200'] <type 'list'>\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('sample.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    reader.next()\n",
    "        \n",
    "    with open('result2.csv', 'w') as fw:\n",
    "        writer = csv.writer(fw)\n",
    "        writer.writerow(['city', 'population'])\n",
    "        \n",
    "        for row in reader:\n",
    "            writer.writerow([row[1], row[2]])\n",
    "            print row, type(row)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* DictReader로 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'city': 'pangyo', 'area': '230', 'id': '1', 'population': '1000'} <type 'dict'>\n",
      "{'city': 'seoul', 'area': '400', 'id': '2', 'population': '2000'} <type 'dict'>\n",
      "{'city': 'busan', 'area': '500', 'id': '3', 'population': '5000'} <type 'dict'>\n",
      "{'city': 'jeju', 'area': '200', 'id': '4', 'population': '200'} <type 'dict'>\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('sample.csv', 'r') as f:\n",
    "    for row in csv.DictReader(f):\n",
    "        print row, type(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 연습문제\n",
    "\n",
    " 1. sample.csv 파일을 읽어서 전체 도시의 평균 인구를 계산하시오.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "5000\n",
      "200\n",
      "2050.0\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('sample.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    reader.next()\n",
    "    \n",
    "    total = 0\n",
    "    cnt = 0\n",
    "    \n",
    "    for row in reader:\n",
    "        print row[2]\n",
    "        total += int(row[2])\n",
    "        cnt += 1\n",
    "        \n",
    "    print total / float(cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "과제)\n",
    "* pycharm 설치하기 (https://www.jetbrains.com/pycharm/)\n",
    "* github 계정 만들기 (http://github.com/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
